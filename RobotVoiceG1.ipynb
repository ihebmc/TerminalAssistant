{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3f125f3-87b5-45d8-b3dc-f652795a7615",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening for wake word...\n",
      "Command received: luna\n",
      "Greeting, Eheb. How can I assist you, my friend?\n",
      "Assistant: Greeting, Eheb. How can I assist you, my friend?\n",
      "Listening for commands...\n",
      "Command received: tell me a joke\n",
      "Processing voice command: tell me a joke\n",
      "Assistant: Why don't scientists trust atoms? Because they make up everything! (Or, why did the scientist go out with a boron atom? Because he couldn't find any carbon monoxide!) Enjoy your day!\n",
      "Listening for commands...\n",
      "Command received: send me another one\n",
      "Processing voice command: send me another one\n",
      "Assistant: Here's a riddle for you: I speak without a mouth and breathe without lungs. What am I?\n",
      "\n",
      "Ponder on it, and let's see if you can guess the answer!\n",
      "Listening for commands...\n",
      "Sorry, I did not understand that.\n",
      "Listening for commands...\n",
      "Command received: what's the answer\n",
      "Processing voice command: what's the answer\n",
      "Assistant: I'd be happy to help, but I need a bit more information. Could you please specify what question or problem you are referring to? This platform is designed to assist with a wide range of topics, from mathematics and science to literature, history, and more. Once I know what you are looking for, I can provide an accurate answer.\n",
      "Listening for commands...\n",
      "Sorry, I did not understand that.\n",
      "Listening for commands...\n",
      "Command received: come on\n",
      "Processing voice command: come on\n",
      "Assistant: Hello! How can I assist you today? If you have any questions or need help with something, feel free to ask. I'm here to help! ðŸ˜Š\n",
      "Listening for commands...\n",
      "Command received: command\n",
      "Switched to command mode\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Command mode active. Type 'ex' to switch back to voice mode:  tell me  a riddle  +  it's answer\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing voice command: tell me  a riddle  +  it's answer\n",
      "Assistant: Riddle: I speak without a mouth and breathe without lungs. What am I?\n",
      "\n",
      "Answer: The wind (or air). It is said to 'speak' by causing sounds when passing through narrow openings, and 'breathes' by moving in and out of spaces.\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Command mode active. Type 'ex' to switch back to voice mode:  ex\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Switched back to listening mode\n",
      "Listening for commands...\n",
      "Command received: thank you\n",
      "Processing voice command: thank you\n",
      "Assistant: You're welcome! If there is anything else I can help you with, feel free to ask. Have a great day!\n",
      "Listening for commands...\n",
      "Command received: no thanks goodbye then\n",
      "Processing voice command: no thanks goodbye then\n",
      "Assistant: Goodbye! Have a wonderful day! If you ever need help or have any questions, feel free to reach out. I'm always here to assist! Stay awesome! ðŸŒŸâœ¨\n",
      "Listening for commands...\n",
      "Sorry, I did not understand that.\n",
      "Listening for commands...\n",
      "Sorry, I did not understand that.\n",
      "Listening for commands...\n",
      "Sorry, I did not understand that.\n",
      "Listening for commands...\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from gtts import gTTS\n",
    "import os\n",
    "import sounddevice as sd\n",
    "import soundfile as sf\n",
    "import threading\n",
    "import time\n",
    "import subprocess\n",
    "import asyncio\n",
    "import functools\n",
    "import tempfile\n",
    "import nest_asyncio\n",
    "from concurrent.futures import ThreadPoolExecutor\n",
    "\n",
    "# Initialize recognizer\n",
    "recognizer = sr.Recognizer()\n",
    "\n",
    "# Global flags for mode switching\n",
    "in_cmd_mode = False\n",
    "assistant_active = False\n",
    "\n",
    "# Define your wake words\n",
    "wake_words = [\"luna\", \"danna\"]\n",
    "\n",
    "# Simple cache for responses\n",
    "response_cache = {}\n",
    "\n",
    "# Create a temporary directory for audio files\n",
    "temp_dir = tempfile.mkdtemp()\n",
    "\n",
    "# Create a ThreadPoolExecutor\n",
    "executor = ThreadPoolExecutor()\n",
    "\n",
    "async def run_in_executor(func, *args):\n",
    "    loop = asyncio.get_event_loop()\n",
    "    return await loop.run_in_executor(executor, func, *args)\n",
    "\n",
    "async def listen():\n",
    "    global in_cmd_mode, assistant_active\n",
    "    while True:\n",
    "        if not in_cmd_mode:\n",
    "            with sr.Microphone() as source:\n",
    "                if not assistant_active:\n",
    "                    print(\"Listening for wake word...\")\n",
    "                else:\n",
    "                    print(\"Listening for commands...\")\n",
    "                audio = recognizer.listen(source)\n",
    "                try:\n",
    "                    command = await run_in_executor(recognizer.recognize_google, audio)\n",
    "                    command = command.lower()\n",
    "                    print(f\"Command received: {command}\")\n",
    "                    if not assistant_active:\n",
    "                        if any(wake_word in command for wake_word in wake_words):\n",
    "                            assistant_active = True\n",
    "                            await greet()\n",
    "                    else:\n",
    "                        if command in [\"command\", \"cmd\"]:\n",
    "                            in_cmd_mode = True\n",
    "                            print(\"Switched to command mode\")\n",
    "                        else:\n",
    "                            await process_voice_command(command)\n",
    "                except sr.UnknownValueError:\n",
    "                    print(\"Sorry, I did not understand that.\")\n",
    "                except sr.RequestError:\n",
    "                    print(\"Sorry, there was an error with the request.\")\n",
    "        await asyncio.sleep(0.1)\n",
    "\n",
    "async def greet():\n",
    "    greeting_text = \"Greeting, Eheb. How can I assist you, my friend?\"\n",
    "    print(greeting_text)\n",
    "    await speak(greeting_text)\n",
    "\n",
    "async def generate_response(prompt):\n",
    "    if prompt in response_cache:\n",
    "        return response_cache[prompt]\n",
    "    \n",
    "    try:\n",
    "        # Run Mistral locally using ollama\n",
    "        result = await run_in_executor(\n",
    "            lambda: subprocess.run(\n",
    "                ['ollama', 'run', 'mistral', prompt],\n",
    "                capture_output=True,\n",
    "                text=True,\n",
    "                check=True,\n",
    "                encoding='utf-8'\n",
    "            )\n",
    "        )\n",
    "        response = result.stdout.strip()\n",
    "        response_cache[prompt] = response\n",
    "        return response\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error running Mistral: {e}\")\n",
    "        return \"Sorry, I couldn't generate a response.\"\n",
    "    except UnicodeDecodeError as e:\n",
    "        print(f\"Error decoding Mistral output: {e}\")\n",
    "        return \"Sorry, there was an error processing the response.\"\n",
    "\n",
    "async def speak(text):\n",
    "    print(\"Assistant:\", text)\n",
    "    tts = gTTS(text=text, lang='en', tld='co.uk')\n",
    "    mp3_path = os.path.join(temp_dir, \"response.mp3\")\n",
    "    wav_path = os.path.join(temp_dir, \"response.wav\")\n",
    "    tts.save(mp3_path)\n",
    "    \n",
    "    # Convert MP3 to WAV\n",
    "    ffmpeg_command = [\n",
    "        \"ffmpeg\",\n",
    "        \"-loglevel\", \"error\",\n",
    "        \"-i\", mp3_path,\n",
    "        \"-acodec\", \"pcm_s16le\",\n",
    "        \"-ar\", \"44100\",\n",
    "        \"-ac\", \"1\",\n",
    "        wav_path,\n",
    "        \"-y\"\n",
    "    ]\n",
    "    \n",
    "    try:\n",
    "        await run_in_executor(lambda: subprocess.run(ffmpeg_command, check=True, capture_output=True))\n",
    "    except subprocess.CalledProcessError as e:\n",
    "        print(f\"Error during audio conversion: {e.stderr}\")\n",
    "        return\n",
    "    \n",
    "    # Read and play WAV file\n",
    "    data, samplerate = await run_in_executor(sf.read, wav_path)\n",
    "    await run_in_executor(sd.play, data, samplerate)\n",
    "    await run_in_executor(sd.wait)\n",
    "    \n",
    "    # Clean up temporary files\n",
    "    os.remove(mp3_path)\n",
    "    os.remove(wav_path)\n",
    "    \n",
    "async def process_voice_command(command):\n",
    "    response_text = await generate_response(command)\n",
    "    if response_text:\n",
    "        print(f\"Processing voice command: {command}\")\n",
    "        await speak(response_text)\n",
    "    else:\n",
    "        print(\"No response text generated.\")\n",
    "\n",
    "async def handle_command_mode():\n",
    "    global in_cmd_mode, assistant_active\n",
    "    while True:\n",
    "        if in_cmd_mode:\n",
    "            cmd_input = await run_in_executor(input, \"Command mode active. Type 'ex' to switch back to voice mode: \")\n",
    "            if cmd_input.lower() == \"ex\":\n",
    "                in_cmd_mode = False\n",
    "                assistant_active = True  # Keep the assistant active when exiting command mode\n",
    "                print(\"Switched back to listening mode\")\n",
    "            else:\n",
    "                await process_voice_command(cmd_input)\n",
    "        await asyncio.sleep(0.1)\n",
    "\n",
    "async def main():\n",
    "    listener_task = asyncio.create_task(listen())\n",
    "    command_mode_task = asyncio.create_task(handle_command_mode())\n",
    "    \n",
    "    try:\n",
    "        await asyncio.gather(listener_task, command_mode_task)\n",
    "    finally:\n",
    "        # Clean up the temporary directory\n",
    "        for file in os.listdir(temp_dir):\n",
    "            os.remove(os.path.join(temp_dir, file))\n",
    "        os.rmdir(temp_dir)\n",
    "        executor.shutdown()\n",
    "\n",
    "nest_asyncio.apply()\n",
    "\n",
    "# Create and run the main coroutine\n",
    "loop = asyncio.get_event_loop()\n",
    "loop.run_until_complete(main())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "465e59b7-7223-4404-b389-a3bd5d254724",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd83927-ddd4-4b15-ab65-b80b944f37f3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "85d18cb4-e1bd-4800-9f4b-7f359472ef41",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18fdf50d-2b27-4f67-8731-2f175557ac0c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b308d51-25cd-4ccf-905a-f67e36da1c41",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (emotionG7)",
   "language": "python",
   "name": "emotiong7"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
